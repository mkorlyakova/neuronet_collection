# -*- coding: utf-8 -*-
"""Untitled.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_25zhOB7BmrA9KpK4mYymkmd7V4zIkuj
"""

import os

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras


import random

import sys
import sys

from tensorflow.keras.preprocessing.image import ImageDataGenerator
sys.path.insert(0,"../autoenc_main")

import matplotlib.pyplot as plt


SIZE = [128,128,3]

latent_dim_ = 256
alf = [0]
epoch_m = 2

batch_size_model = 256+64


class Milani2_FPN_adv(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0, av_max=0, n1=1, fgsm =0.0 , pass_features=False, **kwargs):
        super(Milani2_FPN_adv, self).__init__(**kwargs)

        self.l2_scale = 0.02
        self.pass_features = pass_features

        self.conv0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up0 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf0 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf0')
        self.add0 = tf.keras.layers.Add()
        if av_max:
            self.gp0 = tf.keras.layers.GlobalMaxPooling2D() 
        else:
            self.gp0 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.mp1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))        
        
        self.up1 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf1 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf1')
        self.add1 = tf.keras.layers.Add()
        if av_max:
            self.gp1 = tf.keras.layers.GlobalMaxPooling2D() 
        else:
            self.gp1 = tf.keras.layers.GlobalAveragePooling2D()
        self.conv2 = tf.keras.layers.Conv2D(filters=96, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv2')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.mp2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up2 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf2 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf2')
        self.add2 = tf.keras.layers.Add() 
        if av_max:
            self.gp2 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp2 = tf.keras.layers.GlobalAveragePooling2D()

        self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv3')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.mp3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up3 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf3 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf3')
        self.add3 = tf.keras.layers.Add()
        if av_max:
            self.gp3 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp3 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv4 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv4')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()
        self.mp4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up4 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf4 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf4')
        self.add4 = tf.keras.layers.Add()
        if av_max:
            self.gp4 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp4 = tf.keras.layers.GlobalAveragePooling2D()
                
        self.conv5 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv5')
        self.bn5 = tf.keras.layers.BatchNormalization(name='bn_5')
        self.relu5 = tf.keras.layers.ReLU()
        self.mp5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up5 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf5 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf5')
        self.add5 = tf.keras.layers.Add()       
        if av_max:
            self.gp5 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp5 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv6 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv6')
        self.bn6 = tf.keras.layers.BatchNormalization(name='bn_6')
        self.relu6 = tf.keras.layers.ReLU()
        self.mp6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up6 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf6 = tf.keras.layers.Conv2D(filters=512, kernel_size=(1, 1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf6')
        self.add6 = tf.keras.layers.Add()
        if av_max:
            self.gp6 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp6 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.dn0 = tf.keras.layers.Dense(units=128, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.flat = tf.keras.layers.Flatten(name="features")
       
        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        self.fgsm = fgsm
        
        self.loss_object = tf.keras.losses.CategoricalCrossentropy()
        
    #@tf.function
    def gaussian_blur(self, img, kernel_size=11, sigma=5):
        def gauss_kernel(channels, kernel_size, sigma):
            ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)
            xx, yy = tf.meshgrid(ax, ax)
            kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))
            kernel = kernel / tf.reduce_sum(kernel)
            kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])
            return kernel

        gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)
        gaussian_kernel = gaussian_kernel[..., tf.newaxis]

        return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1], padding='SAME', data_format='NHWC')

    #@tf.function
    def highpass(self, images, kernel_size=11, sigma=5):
        blurred = self.gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    # @tf.function
    # def highpass_median(images, kernel_size=11, sigma=5):
    #     blurred = tfa.image.median_filter2d(image=images)#gaussian_blur(images, kernel_size, sigma)
    #     subtracted = images - blurred
    #
    #     return subtracted, images, blurred

    #@tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    #@tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred


    def resize_to(self, image, sz, keep_scales=False):
        if keep_scales == False:
            return tf.image.resize(images=image, size=(sz, sz))
        else:
            return tf.image.resize_with_pad(image=image, target_height=sz, target_width=sz)

    def resize_filter(self, images, scale=1.0/2.0):
        newsize = int(self.resolution * scale)
        # tf.print(newsize)

        rimages = self.resize_to(image=images, sz=newsize, keep_scales=False)
        r2images = self.resize_to(image=rimages, sz=self.resolution, keep_scales=False)
        noise = images - r2images

        return noise

    
    #FGSM        

    def train_step(self, data):
        x, y = data
        #try:
        if 1:    
            with tf.GradientTape() as tape:
                print('FGSM')
                print(x)
                tape.watch(x)
                y_pred = self(x, training=False)  # Forward pass
                # Compute our own loss
                print('y_pred:',y_pred["logits_softmax"])
                print('y:',y)
                loss = self.loss_object(y, y_pred["logits_softmax"])
                print('loss:',loss)
            gradient = tape.gradient(loss, x) 
            print(gradient)
            signed_grad = tf.sign(gradient)
            x = x + gradient* self.fgsm
                
            #print('fgsm:',x.shape, self.fgsm)
        #except:
        #    pass
        return super(Milani2_FPN_adv,self).train_step((x,y))
        #with tf.GradientTape() as tape:
        #    y_pred = self(x, training=True)  # Forward pass
        #    # Compute our own loss
        #    loss = keras.losses.mean_squared_error(y, y_pred)
        ## Compute gradients
        #trainable_vars = self.trainable_variables
        #gradients = tape.gradient(loss, trainable_vars)
        
        
        # Update weights
        #self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        # Compute our own metrics
        #loss_tracker.update_state(loss)
        #mae_metric.update_state(y, y_pred)
        #return {"loss": loss_tracker.result(), "mae": mae_metric.result()}

    #@tf.function
    def call(self, inputs, training):

        x = inputs
        #tf.print('":"',tf.shape(x))
        original_shape = tf.shape(x)
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])

        if self.mode == 0:
                #print(x.shape)
                #x, x_o, x_b = self.highpass_median(x)
                #x, x_o, x_b = self.jpeg_dif( x, n_jpg=2,q=95, q_Im=10.)
                x, x_o, x_b = self.highpass_median(x)
                

        if self.mode == 0:
            x = self.conv0(x)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x0 = x
            x = self.mp0(x)
            
            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x1 = x
            x = self.mp1(x)
            
            x = self.conv2(x)
            x = self.bn2(x, training)
            x = self.relu2(x)
            x2 = x
            x = self.mp2(x)
            
            x = self.conv3(x)
            x = self.bn3(x, training)
            x = self.relu3(x)
            x3 = x
            x = self.mp3(x)
            
            x = self.conv4(x)
            x = self.bn4(x, training)
            x = self.relu4(x)
            x4 = x
            x = self.mp4(x)

            x = self.conv5(x)
            x = self.bn5(x, training)
            x = self.relu5(x)
            x5 = x
            x = self.mp5(x)
            
            x = self.conv6(x)
            x = self.bn6(x, training)
            x = self.relu6(x)
            x6 = x
            x = self.mp6(x)
            
            x7 = x
            x67 = self.up6(x7)
            x6 = self.convf6(x6)
            #print(x6.shape, x67.shape)
            x67 = self.add6([x6,x67])
            x67g = self.gp6(x67)
            
            x56 = self.up5(x67)
            x5 = self.convf5(x5)
            x56 = self.add5([x5,x56])
            x56g = self.gp5(x56)
            
            x45 = self.up4(x56)
            x4 = self.convf4(x4)
            x45 = self.add4([x4,x45])
            x45g = self.gp4(x45)            
            
            x34 = self.up3(x45)
            x3 = self.convf3(x3)
            x34 = self.add3([x3,x34])
            x34g = self.gp3(x34)
            
            x23 = self.up2(x34)
            x2 = self.convf2(x2)
            x23 = self.add2([x2,x23])
            x23g = self.gp2(x23)
            
            x12 = self.up1(x23)
            x1 = self.convf1(x1)
            x12 = self.add1([x1,x12])
            x12g = self.gp2(x12)
            
            
            x = self.flat(x)
            x = tf.keras.layers.concatenate([x12g,x23g,x34g,x45g,x56g,x67g,x])
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x
            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}




class Milani2_FPN(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0, av_max=0, n1=1, pass_features=False, **kwargs):
        super(Milani2_FPN, self).__init__(**kwargs)

        self.l2_scale = 0.02
        self.pass_features = pass_features

        self.conv0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up0 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf0 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf0')
        self.add0 = tf.keras.layers.Add()
        if av_max:
            self.gp0 = tf.keras.layers.GlobalMaxPooling2D() 
        else:
            self.gp0 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.mp1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))        
        
        self.up1 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf1 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf1')
        self.add1 = tf.keras.layers.Add()
        if av_max:
            self.gp1 = tf.keras.layers.GlobalMaxPooling2D() 
        else:
            self.gp1 = tf.keras.layers.GlobalAveragePooling2D()
        self.conv2 = tf.keras.layers.Conv2D(filters=96, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv2')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.mp2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up2 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf2 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf2')
        self.add2 = tf.keras.layers.Add() 
        if av_max:
            self.gp2 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp2 = tf.keras.layers.GlobalAveragePooling2D()

        self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv3')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.mp3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up3 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf3 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf3')
        self.add3 = tf.keras.layers.Add()
        if av_max:
            self.gp3 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp3 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv4 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv4')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()
        self.mp4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up4 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf4 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf4')
        self.add4 = tf.keras.layers.Add()
        if av_max:
            self.gp4 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp4 = tf.keras.layers.GlobalAveragePooling2D()
                
        self.conv5 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv5')
        self.bn5 = tf.keras.layers.BatchNormalization(name='bn_5')
        self.relu5 = tf.keras.layers.ReLU()
        self.mp5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up5 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf5 = tf.keras.layers.Conv2D(filters=512, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf5')
        self.add5 = tf.keras.layers.Add()       
        if av_max:
            self.gp5 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp5 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv6 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv6')
        self.bn6 = tf.keras.layers.BatchNormalization(name='bn_6')
        self.relu6 = tf.keras.layers.ReLU()
        self.mp6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up6 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf6 = tf.keras.layers.Conv2D(filters=512, kernel_size=(1, 1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf6')
        self.add6 = tf.keras.layers.Add()
        if av_max:
            self.gp6 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp6 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.dn0 = tf.keras.layers.Dense(units=128, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.flat = tf.keras.layers.Flatten(name="features")
       
        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        
    #@tf.function
    def gaussian_blur(self, img, kernel_size=11, sigma=5):
        def gauss_kernel(channels, kernel_size, sigma):
            ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)
            xx, yy = tf.meshgrid(ax, ax)
            kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))
            kernel = kernel / tf.reduce_sum(kernel)
            kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])
            return kernel

        gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)
        gaussian_kernel = gaussian_kernel[..., tf.newaxis]

        return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1], padding='SAME', data_format='NHWC')

    #@tf.function
    def highpass(self, images, kernel_size=11, sigma=5):
        blurred = self.gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    # @tf.function
    # def highpass_median(images, kernel_size=11, sigma=5):
    #     blurred = tfa.image.median_filter2d(image=images)#gaussian_blur(images, kernel_size, sigma)
    #     subtracted = images - blurred
    #
    #     return subtracted, images, blurred

    #@tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    #@tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    def coeffs_by_level(self, coeffs, i, sigma):
        sigma_squared = tf.constant(sigma ** 2, tf.float64)
        h, v, d = coeffs[-1 - i]

        ker3 = tf.ones([3, 3, 3, 3], tf.float64) / (3 ** 2)
        ker5 = tf.ones([5, 5, 3, 3], tf.float64) / (5 ** 2)
        ker7 = tf.ones([7, 7, 3, 3], tf.float64) / (7 ** 2)
        ker9 = tf.ones([9, 9, 3, 3], tf.float64) / (9 ** 2)

        tmp = h ** 2
        var_h3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_h = tf.minimum(var_h3, var_h5)
        var_h = tf.minimum(var_h, var_h7)
        var_h = tf.minimum(var_h, var_h9)

        tmp = v ** 2
        var_v3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_v = tf.minimum(var_v3, var_v5)
        var_v = tf.minimum(var_v, var_v7)
        var_v = tf.minimum(var_v, var_v9)

        tmp = d ** 2
        var_d3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_d = tf.minimum(var_d3, var_d5)
        var_d = tf.minimum(var_d, var_d7)
        var_d = tf.minimum(var_d, var_d9)

        h = h * var_h / (var_h + sigma_squared)
        v = v * var_v / (var_v + sigma_squared)
        d = d * var_d / (var_d + sigma_squared)

        new_coeffs = h, v, d
        return new_coeffs

    def daubechi_filter_without_pywt(self, images, db8, sigma=2.0, return_noise=0):

        """Test"""
        """wavelet_ = Daubechi_wavelet_class.Daubechi_wavelet(2000)
        coeffs = wavelet_.wavedec2(images)
        img_rez = wavelet_.waverec2(coeffs)
        img_rez = tf.minimum(255 * tf.ones_like(img_rez), img_rez)
        img_rez = tf.maximum(tf.zeros_like(img_rez), img_rez)
        img_rez = tf.cast(img_rez, tf.uint8)[0, :, :, :]
        diff = img_rez - images[0, :, :, :]
        max_diff = tf.reduce_max(diff)
        cv2.imshow('filt_img', cv2.cvtColor(img_rez.numpy(), cv2.COLOR_BGR2RGB) )
        cv2.waitKey()"""
        """End test"""


        coeffs = db8.wavedec2(images)

        coeffs0 = self.coeffs_by_level(coeffs, 0, sigma)
        coeffs[-1 - 0] = coeffs0


        filt_img = db8.waverec2(coeffs)
        filt_img = tf.minimum(255 * tf.ones_like(filt_img), filt_img)
        filt_img = tf.maximum(tf.zeros_like(filt_img), filt_img)

        if return_noise > 0:
            noise = tf.cast(images, tf.float64) - filt_img
            result = (noise, images, filt_img)
        else:
            result = filt_img

        return result

    # @tf.function
    def high_db8(self, images, db8, sigma=2.0):
        return self.daubechi_filter_without_pywt(images, db8, sigma=sigma, return_noise=1)

    def haar_filter(self, images, sigma=2.0, return_noise=0):
        level = 1
        coeffs = self.haar_dec2(images, level)


        # for i in tf.range(level):
        coeffs_tmp = self.hcoeffs_by_level(coeffs, 0, sigma)
        coeffs[-1 - 0] = coeffs_tmp


        filt_img = self.haar_rec2(coeffs, level)
        filt_img = tf.minimum(255 * tf.ones_like(filt_img), filt_img)
        filt_img = tf.maximum(tf.zeros_like(filt_img), filt_img)

        # if return_noise > 0:
        #     noise = tf.cast(images, tf.float32) - filt_img
        #     result = (filt_img, noise)
        # else:
        #     result = filt_img
        result = tf.cast(images, tf.float32) - filt_img

        return result



    def haar_dec2(self, batch_bhwc, level=1):
        batch_bhwc = tf.cast(batch_bhwc, tf.float32)


        coeffs_list = []

        low = tf.identity(batch_bhwc)
        # for i in tf.range(level):
        low, hi_coeffs = self.hwt2(low)
        coeffs_list.append(hi_coeffs)

        coeffs_list.append(low)
        coeffs_list.reverse()

        return coeffs_list



    def haar_rec2(self, coeffs, level=1):
        a, ds = coeffs[0], coeffs[1:]


        # for i in tf.range(tf.constant(level, tf.int32)):
        a = self.ihwt2((a, ds[0]))

        return a


    def hwt2(self, batch_bhwc):
        h = (tf.shape(batch_bhwc)[-3] // 2) * 2
        w = (tf.shape(batch_bhwc)[-2] // 2) * 2
        ind_even = tf.range(0, w, 2)
        ind_odd = tf.range(1, w, 2)
        m_even = tf.gather(batch_bhwc, ind_even, axis=2)
        m_odd = tf.gather(batch_bhwc, ind_odd, axis=2)


        half_sum = (m_even + m_odd) / tf.sqrt(2.)
        half_diff = (m_even - m_odd) / tf.sqrt(2.)

        out_step_1 = tf.concat([half_sum, half_diff], axis=2)
        out_step_1 = tf.cond(tf.equal(w, tf.shape(batch_bhwc)[-2]),
                             lambda: out_step_1,
                             lambda: tf.concat([out_step_1, batch_bhwc[:, :, -1:, :]], axis=2)
                             )

        ind_even = tf.range(0, h, 2)
        ind_odd = tf.range(1, h, 2)
        m_even = tf.gather(out_step_1, ind_even, axis=1)
        m_odd = tf.gather(out_step_1, ind_odd, axis=1)
        half_sum = (m_even + m_odd) / tf.sqrt(2.)
        half_diff = (m_even - m_odd) / tf.sqrt(2.)

        out_step_2 = tf.concat([half_sum, half_diff], axis=1)
        out_step_2 = tf.cond(tf.equal(h, tf.shape(batch_bhwc)[-3]),
                             lambda: out_step_2,
                             lambda: tf.concat([out_step_2, out_step_1[:, -1:, :, :]], axis=1)
                             )

        low = out_step_2[:, :(h // 2), :(w // 2), :]
        hor = out_step_2[:, :(h // 2), (w // 2):, :]
        ver = out_step_2[:, (h // 2):, :(w // 2), :]
        dia = out_step_2[:, (h // 2):, (w // 2):, :]

        return low, (hor, ver, dia)


    def ihwt2(self, coeffs):
        low, (hor, ver, dia) = coeffs


        concat_1 = tf.concat([low, hor], axis=2)
        concat_2 = tf.concat([ver, dia], axis=2)
        out_preproc = tf.concat([concat_1, concat_2], axis=1)

        h = tf.shape(out_preproc)[-3] // 2
        w = tf.shape(out_preproc)[-2] // 2

        out = tf.identity(out_preproc)

        updates_even = (out_preproc[:, :h, :, :] + out_preproc[:, h:2 * h, :, :]) / tf.sqrt(2.)
        updates_odd = (out_preproc[:, :h, :, :] - out_preproc[:, h:2 * h, :, :]) / tf.sqrt(2.)

        updates_even = tf.reshape(updates_even, [tf.shape(updates_even)[0] * tf.shape(updates_even)[1] *
                                                 tf.shape(updates_even)[2] * tf.shape(updates_even)[3]])
        updates_odd = tf.reshape(updates_odd, [tf.shape(updates_odd)[0] * tf.shape(updates_odd)[1] *
                                               tf.shape(updates_odd)[2] * tf.shape(updates_odd)[3]])

        start = tf.constant([[1], [0]], tf.float32)
        start = tf.expand_dims(tf.expand_dims(start, 0), -1)
        indexes_basis = tf.tile(start, [tf.shape(out)[0], h, tf.shape(out)[2], tf.shape(out)[3]])
        indexes = tf.cast(tf.where(tf.greater(indexes_basis, 0.5)), tf.int32)
        out = tf.tensor_scatter_nd_update(out, indexes, updates_even)

        indexes = tf.cast(tf.where(tf.less(indexes_basis, 0.5)), tf.int32)
        out = tf.tensor_scatter_nd_update(out, indexes, updates_odd)

        updates_even = (out[:, :, :w, :] + out[:, :, w:2 * w, :]) / tf.sqrt(2.)
        updates_odd = (out[:, :, :w, :] - out[:, :, w:2 * w, :]) / tf.sqrt(2.)

        updates_even = tf.reshape(updates_even, [tf.shape(updates_even)[0] * tf.shape(updates_even)[1] *
                                                 tf.shape(updates_even)[2] * tf.shape(updates_even)[3]])
        updates_odd = tf.reshape(updates_odd, [tf.shape(updates_odd)[0] * tf.shape(updates_odd)[1] *
                                               tf.shape(updates_odd)[2] * tf.shape(updates_odd)[3]])

        start = tf.constant([[1, 0]], tf.float32)
        start = tf.expand_dims(tf.expand_dims(start, 0), -1)
        indexes_basis = tf.tile(start, [tf.shape(out)[0], tf.shape(out)[1], w, tf.shape(out)[3]])
        indexes = tf.cast(tf.where(tf.greater(indexes_basis, 0.5)), tf.int32)
        out = tf.tensor_scatter_nd_update(out, indexes, updates_even)

        indexes = tf.cast(tf.where(tf.less(indexes_basis, 0.5)), tf.int32)
        out = tf.tensor_scatter_nd_update(out, indexes, updates_odd)
        return out

    def hcoeffs_by_level(self, coeffs, i, sigma):
        sigma_squared = tf.constant(sigma ** 2, tf.float32)
        h, v, d = coeffs[-1 - i]


        ker3 = tf.ones([3, 3, 3, 3], tf.float32) / (3 ** 2)
        ker5 = tf.ones([5, 5, 3, 3], tf.float32) / (5 ** 2)
        ker7 = tf.ones([7, 7, 3, 3], tf.float32) / (7 ** 2)
        ker9 = tf.ones([9, 9, 3, 3], tf.float32) / (9 ** 2)

        tmp = h ** 2
        var_h3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_h = tf.minimum(var_h3, var_h5)
        var_h = tf.minimum(var_h, var_h7)
        var_h = tf.minimum(var_h, var_h9)

        tmp = v ** 2
        var_v3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_v = tf.minimum(var_v3, var_v5)
        var_v = tf.minimum(var_v, var_v7)
        var_v = tf.minimum(var_v, var_v9)

        tmp = d ** 2
        var_d3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_d = tf.minimum(var_d3, var_d5)
        var_d = tf.minimum(var_d, var_d7)
        var_d = tf.minimum(var_d, var_d9)

        h = h * var_h / (var_h + sigma_squared)
        v = v * var_v / (var_v + sigma_squared)
        d = d * var_d / (var_d + sigma_squared)

        new_coeffs = h, v, d
        return new_coeffs

    def resize_to(self, image, sz, keep_scales=False):
        if keep_scales == False:
            return tf.image.resize(images=image, size=(sz, sz))
        else:
            return tf.image.resize_with_pad(image=image, target_height=sz, target_width=sz)

    def resize_filter(self, images, scale=1.0/2.0):
        newsize = int(self.resolution * scale)
        # tf.print(newsize)
        rimages = self.resize_to(image=images, sz=newsize, keep_scales=False)
        r2images = self.resize_to(image=rimages, sz=self.resolution, keep_scales=False)
        noise = images - r2images

        return noise
    def jpeg_dif( self,images, n_jpg=2,q=95, q_Im=10.):
        sh = tf.shape(images)
        print(sh)
        out_IMAGEs = []
        if len(sh) == 4:
            print('muli image')
            for k in range(sh[0]):
                image_ = images[k, :, :, :]
                out_IMAGE = tf.image.convert_image_dtype(image_, tf.float32)
                out_IMAGE =  out_IMAGE/tf.math.reduce_max(out_IMAGE)
                image_ = tf.image.convert_image_dtype(image_, tf.uint8)
                print('im:',image_.shape)
                for i in range(n_jpg):
                    blurred_jpg = tf.io.encode_jpeg(image_, quality=q)
                    blurred = tf.io.decode_jpeg(blurred_jpg)
                    print(blurred.shape)
                    subtracted = tf.image.convert_image_dtype(image_, tf.float32)*q_Im-tf.image.convert_image_dtype(blurred, tf.float32)*q_Im

                    out_IMAGE = tf.concat([out_IMAGE, subtracted], axis=-1)
                    image_ = blurred
                out_IMAGEs += [tf.reshape(out_IMAGE,[1,sh[-3],sh[-2], 3 * (n_jpg + 1)])]
                print(len(out_IMAGEs))
            out_IMAGEs = tf.concat(out_IMAGEs,  axis=0)
            print(out_IMAGEs.shape)
            #out_IMAGEs = tf.reshape(out_IMAGE, [-1, sh[-3], sh[-2], 3 * (n_jpg + 1)])
        else:
            print('ones image')
            image_ = images
            out_IMAGE = tf.image.convert_image_dtype(image_, tf.float32)
            out_IMAGE = out_IMAGE / tf.math.reduce_max(out_IMAGE)
            image_ = tf.image.convert_image_dtype(image_, tf.uint8)
            for i in range(n_jpg):
                blurred_jpg = tf.io.encode_jpeg(image_,quality=q)
                blurred = tf.io.decode_jpeg(blurred_jpg )
                print('blur:',blurred.shape)
                subtracted = tf.image.convert_image_dtype(image_, tf.float32)*q_Im-tf.image.convert_image_dtype(blurred, tf.float32)*q_Im
                out_IMAGE = tf.concat([out_IMAGE, subtracted], axis=-1)
                image_ = blurred
            out_IMAGEs = tf.reshape(out_IMAGE,[1,sh[-3],sh[-2],3*(n_jpg+1)])

        return out_IMAGEs, images, blurred

    #@tf.function
    def call(self, inputs, training):

        x = inputs
        #tf.print('":"',tf.shape(x))
        original_shape = tf.shape(x)
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])

        if self.mode == 0:
                #print(x.shape)
                #x, x_o, x_b = self.highpass_median(x)
                #x, x_o, x_b = self.jpeg_dif( x, n_jpg=2,q=95, q_Im=10.)
                x, x_o, x_b = self.highpass_median(x)
                

        if self.mode == 0:
            x = self.conv0(x)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x0 = x
            x = self.mp0(x)
            
            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x1 = x
            x = self.mp1(x)
            
            x = self.conv2(x)
            x = self.bn2(x, training)
            x = self.relu2(x)
            x2 = x
            x = self.mp2(x)
            
            x = self.conv3(x)
            x = self.bn3(x, training)
            x = self.relu3(x)
            x3 = x
            x = self.mp3(x)
            
            x = self.conv4(x)
            x = self.bn4(x, training)
            x = self.relu4(x)
            x4 = x
            x = self.mp4(x)

            x = self.conv5(x)
            x = self.bn5(x, training)
            x = self.relu5(x)
            x5 = x
            x = self.mp5(x)
            
            x = self.conv6(x)
            x = self.bn6(x, training)
            x = self.relu6(x)
            x6 = x
            x = self.mp6(x)
            
            x7 = x
            x67 = self.up6(x7)
            x6 = self.convf6(x6)
            #print(x6.shape, x67.shape)
            x67 = self.add6([x6,x67])
            x67g = self.gp6(x67)
            
            x56 = self.up5(x67)
            x5 = self.convf5(x5)
            x56 = self.add5([x5,x56])
            x56g = self.gp5(x56)
            
            x45 = self.up4(x56)
            x4 = self.convf4(x4)
            x45 = self.add4([x4,x45])
            x45g = self.gp4(x45)            
            
            x34 = self.up3(x45)
            x3 = self.convf3(x3)
            x34 = self.add3([x3,x34])
            x34g = self.gp3(x34)
            
            x23 = self.up2(x34)
            x2 = self.convf2(x2)
            x23 = self.add2([x2,x23])
            x23g = self.gp2(x23)
            
            x12 = self.up1(x23)
            x1 = self.convf1(x1)
            x12 = self.add1([x1,x12])
            x12g = self.gp2(x12)
            
            
            x = self.flat(x)
            x = tf.keras.layers.concatenate([x12g,x23g,x34g,x45g,x56g,x67g,x])
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x
            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}


class Milani2_FPN2(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0, av_max=0, n1=1, pass_features=False,schema = [1,1,1,1,1,1,1], n_filters = 512, k_n = 4 , n_p = 512, fgsm = 0 ,**kwargs):
        super(Milani2_FPN2, self).__init__(**kwargs)

        self.l2_scale = 0.02
        self.pass_features = pass_features
        self.sh = schema
        self.fgsm = fgsm
        self.conv0 = tf.keras.layers.Conv2D(filters=8*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up0 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf0 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf0')
        self.add0 = tf.keras.layers.Add()
        self.convp0 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp0')
        if av_max:
            self.gp0 = tf.keras.layers.GlobalMaxPooling2D() 
        else:
            self.gp0 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv1 = tf.keras.layers.Conv2D(filters=16*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.mp1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))        
        
        self.up1 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf1 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf1')
        self.add1 = tf.keras.layers.Add()
        self.convp1 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp1')        
        if av_max:
            self.gp1 = tf.keras.layers.GlobalMaxPooling2D() 
        else:
            self.gp1 = tf.keras.layers.GlobalAveragePooling2D()
        self.conv2 = tf.keras.layers.Conv2D(filters=24*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv2')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.mp2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up2 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf2 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf2')
        self.add2 = tf.keras.layers.Add() 
        self.convp2 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp2')        
        if av_max:
            self.gp2 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp2 = tf.keras.layers.GlobalAveragePooling2D()

        self.conv3 = tf.keras.layers.Conv2D(filters=32*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv3')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.mp3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.up3 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf3 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf3')
        self.add3 = tf.keras.layers.Add()
        self.convp3 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp3')        
        if av_max:
            self.gp3 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp3 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv4 = tf.keras.layers.Conv2D(filters=32*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv4')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()
        self.mp4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up4 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf4 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf4')
        self.add4 = tf.keras.layers.Add()
        self.convp4 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp4')        
        if av_max:
            self.gp4 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp4 = tf.keras.layers.GlobalAveragePooling2D()
                
        self.conv5 = tf.keras.layers.Conv2D(filters=64*k_n, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv5')
        self.bn5 = tf.keras.layers.BatchNormalization(name='bn_5')
        self.relu5 = tf.keras.layers.ReLU()
        self.mp5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up5 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf5 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf5')
        self.add5 = tf.keras.layers.Add()       
        self.convp5 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp5')        
        if av_max:
            self.gp5 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp5 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv6 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv6')
        self.bn6 = tf.keras.layers.BatchNormalization(name='bn_6')
        self.relu6 = tf.keras.layers.ReLU()
        self.mp6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up6 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf6 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(1, 1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf6')
        self.add6 = tf.keras.layers.Add()
        self.convp6 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(1, 1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp6')        
        
        if av_max:
            self.gp6 = tf.keras.layers.GlobalMaxPooling2D()    
        else:
            self.gp6 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.dn0 = tf.keras.layers.Dense(units=128, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.flat = tf.keras.layers.Flatten(name="features")
       
        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        
    #@tf.function
    def gaussian_blur(self, img, kernel_size=11, sigma=5):
        def gauss_kernel(channels, kernel_size, sigma):
            ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)
            xx, yy = tf.meshgrid(ax, ax)
            kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))
            kernel = kernel / tf.reduce_sum(kernel)
            kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])
            return kernel

        gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)
        gaussian_kernel = gaussian_kernel[..., tf.newaxis]

        return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1], padding='SAME', data_format='NHWC')

    #@tf.function
    def highpass(self, images, kernel_size=11, sigma=5):
        blurred = self.gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    # @tf.function
    # def highpass_median(images, kernel_size=11, sigma=5):
    #     blurred = tfa.image.median_filter2d(image=images)#gaussian_blur(images, kernel_size, sigma)
    #     subtracted = images - blurred
    #
    #     return subtracted, images, blurred

    #@tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    #@tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    def resize_to(self, image, sz, keep_scales=False):
        if keep_scales == False:
            return tf.image.resize(images=image, size=(sz, sz))
        else:
            return tf.image.resize_with_pad(image=image, target_height=sz, target_width=sz)

    def resize_filter(self, images, scale=1.0/2.0):
        newsize = int(self.resolution * scale)
        # tf.print(newsize)
        rimages = self.resize_to(image=images, sz=newsize, keep_scales=False)
        r2images = self.resize_to(image=rimages, sz=self.resolution, keep_scales=False)
        noise = images - r2images

        return noise
    

    #@tf.function
    def call(self, inputs, training):

        x = inputs
        #tf.print('":"',tf.shape(x))
        original_shape = tf.shape(x)
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])

        if self.mode == 0:
                #print(x.shape)
                #x, x_o, x_b = self.highpass_median(x)
                #x, x_o, x_b = self.jpeg_dif( x, n_jpg=2,q=95, q_Im=10.)
                x, x_o, x_b = self.highpass_median(x)
        
        if self.mode == 0:
            x = self.conv0(x)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x0 = x
            x = self.mp0(x)
            
            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x1 = x
            x = self.mp1(x)
            
            x = self.conv2(x)
            x = self.bn2(x, training)
            x = self.relu2(x)
            x2 = x
            x = self.mp2(x)
            
            x = self.conv3(x)
            x = self.bn3(x, training)
            x = self.relu3(x)
            x3 = x
            x = self.mp3(x)
            
            x = self.conv4(x)
            x = self.bn4(x, training)
            x = self.relu4(x)
            x4 = x
            x = self.mp4(x)

            x = self.conv5(x)
            x = self.bn5(x, training)
            x = self.relu5(x)
            x5 = x
            x = self.mp5(x)
            
            x = self.conv6(x)
            x = self.bn6(x, training)
            x = self.relu6(x)
            x6 = x
            x = self.mp6(x)
            
            x7 = x
            
            list_x = []
            x67 = self.up6(x7)
            x6 = self.convf6(x6)
            print('6:',x6.shape, x67.shape)
            x67 = self.add6([x6,x67])
            if self.sh[5]:
                print('6:',x67.shape)
                x67_ = self.convp6(x67)
                print('6:',x67_.shape)
                x67g = self.gp6(x67_)
                print('6:', x67g.shape)
                list_x += [x67g]
            
            x56 = self.up5(x67)
            print('5:',x56.shape,x5.shape)
            x5 = self.convf5(x5)
            print('5:',x5.shape)
            x56 = self.add5([x5,x56])
            print('5:',x5.shape, x56.shape)
            if self.sh[4]:
                x56_ = self.convp5(x56)
                print('5:',x56_.shape)
                x56g = self.gp5(x56_)
                print('5:',x56g.shape)
                list_x += [x56g]
            
            x45 = self.up4(x56)
            print('4:',x45.shape)
            x4 = self.convf4(x4)
            print('4:',x4.shape)
            x45 = self.add4([x4,x45])
            print('4:',x4.shape, x45.shape)
            if self.sh[3]:
                x45_ = self.convp4(x45)
                print('4:',x45_.shape)
                x45g = self.gp4(x45_)
                print('4:',x45.shape)
                list_x += [x45g]
            
            x34 = self.up3(x45)
            x3 = self.convf3(x3)
            x34 = self.add3([x3,x34])
            print('3:',x3.shape, x34.shape)
            if self.sh[2]:
                x34_ = self.convp3(x34)
                x34g = self.gp3(x34_)
                list_x += [x34g]
            
            x23 = self.up2(x34)
            x2 = self.convf2(x2)
            x23 = self.add2([x2,x23])
            print('2:',x2.shape, x23.shape)
            if self.sh[1]:
                x23_ = self.convp2(x23)
                x23g = self.gp2(x23_)
                list_x += [x23g]
            
            x12 = self.up1(x23)
            x1 = self.convf1(x1)
            x12 = self.add1([x1,x12])
            print('1:',x1.shape, x12.shape)
            if self.sh[0]:
                x12_ = self.convp1(x12)
                x12g = self.gp2(x12_)
                list_x += [x12g]
            
            x = self.flat(x)
            if self.sh[6]:
                x = tf.keras.layers.concatenate(list_x + [x])
            else:
                x = tf.keras.layers.concatenate(list_x)
  
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x
            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}

    


class ASPPBlock(tf.keras.Model):
    def __init__(self,filter_numb = 256, dil_f = [6,12,18], wide = 0):
        super().__init__()
        self.conv1 = tf.keras.layers.Conv2D(filter_numb, (1, 1), padding='same', activation='relu')
        self.conv2 = tf.keras.layers.Conv2D(filter_numb, (3, 3), dilation_rate=dil_f[0], padding='same', activation='relu')
        self.conv3 = tf.keras.layers.Conv2D(filter_numb, (3, 3), dilation_rate=dil_f[1], padding='same', activation='relu')
        self.conv4 = tf.keras.layers.Conv2D(filter_numb, (3, 3), dilation_rate=dil_f[2], padding='same', activation='relu')
        if wide:
            self.conv5 = tf.keras.layers.Conv2D(filter_numb*5,(1,1),padding = 'same')
        else:    
            self.conv5 = tf.keras.layers.Conv2D(32, (1, 1), padding='same', activation='relu')

    def call(self, inp, is_training=False):
        out1 = self.conv1(inp)
        out2 = self.conv2(inp)
        out3 = self.conv3(inp)
        out4 = self.conv4(inp)
        print('aspp_block:',inp.shape,out1.shape,out2.shape,out3.shape,out4.shape)
        out = tf.concat([inp , out1, out2, out3, out4], axis=3)
        print('aspp_concat',out.shape)
        out = self.conv5(out)
        print('aspp_out:',out.shape)
        return out

# In[115]:



class ASPPNet(tf.keras.Model):
 def __init__(self, numb=1,numb_k=16, dil_filter = [6,12,18]):
     super().__init__()
     self.conv1 = tf.keras.layers.Conv2D(4*numb_k, (3, 3), padding='same', activation='relu')
     self.conv2 = tf.keras.layers.Conv2D(4*numb_k, (3, 3), padding='same', activation='relu')
     self.conv3 = tf.keras.layers.Conv2D(8*numb_k, (3, 3), padding='same', activation='relu')
     self.conv4 = tf.keras.layers.Conv2D(8*numb_k, (3, 3), padding='same', activation='relu')
     self.conv5 = tf.keras.layers.Conv2D(16*numb_k, (3, 3), padding='same', activation='relu')
     self.conv6 = tf.keras.layers.Conv2D(16*numb_k, (3, 3), padding='same', activation='relu')
     self.conv7 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
     self.conv8 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
     self.conv9 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
     self.conv10 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')

     self.conv11 = tf.keras.layers.Conv2D(48, (1, 1), padding='same', activation='relu')
     self.conv12 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
     self.conv13 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
     self.conv14 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)
     self.f1 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)

     self.maxpool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')

     self.aspp0 = ASPPBlock(filter_numb = 8*numb, dil_f = dil_filter)
     self.aspp1 = ASPPBlock(filter_numb = 16*numb, dil_f = dil_filter)
     self.aspp2 = ASPPBlock(filter_numb = 32*numb, dil_f = dil_filter)
     self.aspp3 = ASPPBlock(filter_numb = 64*numb, dil_f = dil_filter)

 def call(self, x):

     
     out = self.conv1(x)
     out = self.conv2(out)

     out0 = self.aspp0(out)
     print('aspp0:',out.shape,out0.shape)
     out = self.maxpool(out)#64
     out = self.conv3(out)
     out = self.conv4(out)
     out1 = self.aspp1(out)
     print('aspp1:',out1.shape)

     out = self.maxpool(out)#32

     out = self.conv5(out)
     out = self.conv6(out)
     out2 = self.aspp2(out)
     print('aspp2:',out2.shape)


     out = self.maxpool(out)#16
     out = self.conv7(out)
     out = self.conv8(out)
     out3 = self.aspp3(out)
     print('aspp3:',out3.shape)

     out = self.maxpool(out)#8
     out = self.conv9(out)
     out = self.conv10(out)

     #out = self.aspp(out)

     out0 = tf.image.resize(out0, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)
     out1 = tf.image.resize(out1, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)
     out2 = tf.image.resize(out2, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)
     out3 = tf.image.resize(out3, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)
     out = tf.image.resize(out, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)

     out_enc_mid = self.conv11(x)
     print('outx:',out_enc_mid.shape)

     out = tf.concat([out,out1,out2,out3,out0, out_enc_mid], axis=3)
     print('aspp_out:', out.shape)
     return out

class ASPPNetSeg(tf.keras.Model):
    
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0, numb=1,numb_k=1, dil_filter = [6,12,18],pass_features=False, **kwargs):
        super(ASPPNetSeg, self).__init__(**kwargs)
        
        self.l2_scale = 0.02
        self.conv1 = tf.keras.layers.Conv2D(4*numb_k, (3, 3), padding='same', activation='relu')
        self.conv2 = tf.keras.layers.Conv2D(4*numb_k, (3, 3), padding='same', activation='relu')
        self.conv3 = tf.keras.layers.Conv2D(8*numb_k, (3, 3), padding='same', activation='relu')
        self.conv4 = tf.keras.layers.Conv2D(8*numb_k, (3, 3), padding='same', activation='relu')
        self.conv5 = tf.keras.layers.Conv2D(16*numb_k, (3, 3), padding='same', activation='relu')
        self.conv6 = tf.keras.layers.Conv2D(16*numb_k, (3, 3), padding='same', activation='relu')
        self.conv7 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
        self.conv8 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
        self.conv9 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
        self.conv10 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
    
        self.conv11 = tf.keras.layers.Conv2D(48, (1, 1), padding='same', activation='relu')
        # self.conv12 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
        # self.conv13 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
        self.conv14 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)
        self.f1 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)
        self.maxpool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')
    
        self.aspp0 = ASPPBlock(filter_numb = 8*numb, dil_f = dil_filter, wide=1)
        self.aspp1 = ASPPBlock(filter_numb = 16*numb, dil_f = dil_filter, wide=1)
        self.aspp2 = ASPPBlock(filter_numb = 32*numb, dil_f = dil_filter,wide = 1)
        self.aspp3 = ASPPBlock(filter_numb = 64*numb, dil_f = dil_filter, wide=1)
     
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()     
    
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()        
     
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()   
        
        self.bn00 = tf.keras.layers.BatchNormalization(name='bn_00')
        self.bn10 = tf.keras.layers.BatchNormalization(name='bn_10')
        self.bn20 = tf.keras.layers.BatchNormalization(name='bn_20')
        self.bn30 = tf.keras.layers.BatchNormalization(name='bn_30')
        self.bn40 = tf.keras.layers.BatchNormalization(name='bn_40')
        
        self.bn01 = tf.keras.layers.BatchNormalization(name='bn_01')
        self.bn11 = tf.keras.layers.BatchNormalization(name='bn_11')
        self.bn21 = tf.keras.layers.BatchNormalization(name='bn_21')
        self.bn31 = tf.keras.layers.BatchNormalization(name='bn_31')
        self.bn41 = tf.keras.layers.BatchNormalization(name='bn_41')
        self.mp8 = tf.keras.layers.MaxPooling2D((8,8))
        self.fl = tf.keras.layers.Flatten()
        
        self.dn0 = tf.keras.layers.Dense(units=128, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
     
        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        self.pass_features = pass_features
   

    @tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    @tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred        

    @tf.function
    def call(self, x, training):
        
        original_shape = tf.shape(x)
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])
        
        
        if self.mode == 0:
            x, x_o, x_b = self.highpass_median(x)        
        
                     
        out = self.conv1(x)
        out = self.conv2(out)
        out = self.bn00(out)
        out0 = self.aspp0(out)
        out0 = self.bn01(out0)   
        print('aspp0:',out.shape,out0.shape)
        out = self.maxpool(out)#64
        out = self.conv3(out)
        out = self.conv4(out)
        out = self.bn10(out)   
        out1 = self.aspp1(out)
        out1 = self.bn11(out1)
        print('aspp1:',out1.shape)

        out = self.maxpool(out)#32

        out = self.conv5(out)
        out = self.conv6(out)
        out = self.bn20(out)
        out2 = self.aspp2(out)
        out2 = self.bn21(out2)   
        print('aspp2:',out2.shape)


        out = self.maxpool(out)#16
        out = self.conv7(out)
        out = self.conv8(out)
        out = self.bn30(out)   
        out3 = self.aspp3(out)
        out3 = self.bn31(out3)
        print('aspp3:',out3.shape)

        out = self.maxpool(out)#8
        out = self.conv9(out)
        out = self.conv10(out)
        out = self.bn41(out)
     
        #out = self.aspp(out)

        out0 = tf.image.resize(out0, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)
        out1 = tf.image.resize(out1, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)
        out2 = tf.image.resize(out2, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)
        out3 = tf.image.resize(out3, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)
        out = tf.image.resize(out, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)

        out_enc_mid = self.conv11(x)
        print('outx:',out_enc_mid.shape)

        out = tf.concat([out,out1,out2,out3,out0, out_enc_mid], axis=3)
        print(out.shape)
        out = self.f1(out)
        outS = self.mp8(out)
        print('flatt',outS.shape)
        outS = self.fl(outS)
        outS = self.bn3(outS)
        outS = self.dn0(outS)
        print('aspp_out:', out.shape)
        outS = self.bn4(outS)
        outS = self.relu4(outS)
        outS = self.dropout(outS)
        outS = self.dn1(outS)
     
        logits = outS   
        if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])   
        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}


#model = ASPPNet()
class ASPPNet_new(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0,n8=8, aspp_mod = [4,8,16],numb=4, pass_features=False, **kwargs):
        super(ASPPNet_new, self).__init__(**kwargs)
        dil_filter = aspp_mod
        numb_k = n8
        self.conv1 = tf.keras.layers.Conv2D(4*numb_k, (3, 3), padding='same')
        self.conv2 = tf.keras.layers.Conv2D(4*numb_k, (3, 3), padding='same')
        self.conv3 = tf.keras.layers.Conv2D(8*numb_k, (3, 3), padding='same', activation='relu')
        self.conv4 = tf.keras.layers.Conv2D(8*numb_k, (3, 3), padding='same', activation='relu')
        self.conv5 = tf.keras.layers.Conv2D(16*numb_k, (3, 3), padding='same', activation='relu')
        self.conv6 = tf.keras.layers.Conv2D(16*numb_k, (3, 3), padding='same', activation='relu')
        self.conv7 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
        self.conv8 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
        self.conv9 = tf.keras.layers.Conv2D(32*numb_k, (3, 3), padding='same', activation='relu')
        self.conv10 = tf.keras.layers.Conv2D(512, (1, 1), padding='same', activation='relu')
        self.conv11 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')
        self.conv12 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')
        self.conv13 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')
        self.conv14 = tf.keras.layers.Conv2D(1, (3, 3), padding='same',strides=(2,2), activation=None)
        self.f1 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)
        self.maxpool1 = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')
        self.aspp0 = ASPPBlock(filter_numb = 8*numb,dil_f = dil_filter, wide = 1)
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.maxpool2 = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.bn5 = tf.keras.layers.BatchNormalization(name='bn_5')
        self.bn6 = tf.keras.layers.BatchNormalization(name='bn_6')
        self.bn7 = tf.keras.layers.BatchNormalization(name='bn_7')
        self.relu2 = tf.keras.layers.ReLU()
        self.add1 = tf.keras.layers.Add()
        self.add2 = tf.keras.layers.Add()
        self.flatten = tf.keras.layers.Flatten()
        self.dn0 = tf.keras.layers.Dense(units=128, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        self.pass_features = pass_features

    #@tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")
            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")
            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)
                
            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area
            output = tf.nn.depthwise_conv2d(image, kernel, strides=(1, 1, 1, 1), padding="SAME")
            if rank == 3:
                output = tf.squeeze(output, axis=0)
            return output


    #@tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred
        return subtracted, images, blurred
    #@tf.function
    def call(self, inputs, training):
        
        x = inputs
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])

        original_shape = tf.shape(x)
        
        if self.mode == 0:
            x, x_o, x_b = self.highpass_median(x)
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu1(out)
        out = self.conv2(out)
        out0 = self.aspp0(out)
        print('aspp0:',out.shape,out0.shape)
        out = self.bn2(out0)
        out = self.relu2(out)
        out = self.conv10(out)
        out = self.bn3(out)
        
        out1 = self.maxpool1(out)#64
        print('maxpool:',out.shape,out1.shape)
        out = self.conv12(out1)
        out = self.bn4(out)
        out = self.conv13(out)
        out = self.add1([out1,out])
        out = self.bn5(out)
        
        out2 = self.maxpool2(out)#32
        print('maxpool2:',out.shape,out2.shape)
        out = self.conv11(out2)
        out = self.bn6(out)
        out = self.conv14(out)#16x1
        out = self.bn7(out)
        print('to flatten:',out.shape)
        out = self.flatten(out)
        f = out
        print('flatt:',x.shape)
        x = self.dn0(out)   
        x = self.dropout(x, training)
        x = self.dn1(x)
        logits = x
        if training == False:
            logits = tf.reshape(logits, [original_shape[0], -1, 2])
        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}


# In[116]:
class Milani_PSP(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0,n8=8, aspp_mod = [6,12,18],short=0, pass_features=False, **kwargs):
        super(Milani_PSP, self).__init__(**kwargs)

        self.l2_scale = 0.02
        self.pass_features = pass_features
        #128
        self.aspp = ASPPNet(numb=n8, dil_filter = aspp_mod)
        self.conv0 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.GlobalMaxPooling2D()
        #64


        self.conv1 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()



        self.dn0 = tf.keras.layers.Dense(units=128, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode

    @tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    @tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred        
    @tf.function
    def call(self, inputs, training):
        x = inputs
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])
        
        original_shape = tf.shape(x)
        #print(x.shape)

        if self.mode == 0:
            x, x_o, x_b = self.highpass_median(x)


        if self.mode != 3:

            x = self.aspp(x)
            print('aspp:',x.shape)
            x = self.conv0(x)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x = self.mp0(x)
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x
            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}
    
                           
class Milani2_PSP(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0,n8=8, aspp_mod = [6,12,18],short=0, pass_features=False, **kwargs):
        super(Milani2_PSP, self).__init__(**kwargs)

        self.l2_scale = 0.02
        self.pass_features = pass_features
        #128
        self.aspp = ASPPNet(numb=n8, dil_filter = aspp_mod)
        self.conv0 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        #64


        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.mp1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.conv2 = tf.keras.layers.Conv2D(filters=96, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv2')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.mp2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv3')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.mp3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.conv4 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv4')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()
        self.mp4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.conv5 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv5')
        self.bn5 = tf.keras.layers.BatchNormalization(name='bn_5')
        self.relu5 = tf.keras.layers.ReLU()
        self.mp5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.conv6 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv6')
        self.bn6 = tf.keras.layers.BatchNormalization(name='bn_6')
        self.relu6 = tf.keras.layers.ReLU()
        self.mp6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))



        self.dn0 = tf.keras.layers.Dense(units=128, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.flat = tf.keras.layers.Flatten(name="features")
        # self.pool = tf.keras.layers.GlobalMaxPool2D()
        # self.lnorm = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))
        # self.dropout = tf.keras.layers.Dropout(dropout, name="dropout")
        # self.dn0 = tf.keras.layers.Dense(units=20, activation='relu',
        #                                  # kernel_regularizer=tf.keras.regularizers.l2(l=self.l2_scale),
        #                                  kernel_initializer=tf.keras.initializers.glorot_uniform())
        # self.classifier = tf.keras.layers.Dense(units=2, activation=None,
        #                                         # kernel_regularizer=tf.keras.regularizers.l2(l=self.l2_scale),
        #                                         kernel_initializer=tf.keras.initializers.glorot_uniform(),
        #                                         name="dense_classes")

        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        if self.mode == 2 or self.mode == 3 or self.mode == 4 or self.mode == 5:
            self.db8 = Daubechi_wavelet(250)

    # @tf.function
    def gaussian_blur(self, img, kernel_size=11, sigma=5):
        def gauss_kernel(channels, kernel_size, sigma):
            ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)
            xx, yy = tf.meshgrid(ax, ax)
            kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))
            kernel = kernel / tf.reduce_sum(kernel)
            kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])
            return kernel

        gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)
        gaussian_kernel = gaussian_kernel[..., tf.newaxis]

        return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1], padding='SAME', data_format='NHWC')

    # @tf.function
    def highpass(self, images, kernel_size=11, sigma=5):
        blurred = self.gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred
    def jpeg_dif(self, images,n_jpg = 2):
        sh  = tf.shape(images)

        out_IMAGEs = []
        if len(sh) == 4:
            for k in range(sh[0]):
                image_ = images[k,:,:,:]
                out_IMAGE = [image_]
                #image_ = tf.image.convert_image_dtype(image_,tf.uint8)
                for i in range(n_jpg):
                    blurred_jpg = tf.io.encode_jpeg(image_)
                    blurred = tf.io.decode_jpeg(blurred_jpg, q = 95)
                    subtracted = tf.cast(image_,dtype=tf.float32)/255 - tf.cast(blurred,dtype=tf.float32)/255
                
                    out_IMAGE = tf.concat([out_IMAGE, subtracted], axis=-1)
                    image_ = blurred
                out_IMAGEs +=[out_IMAGE]
        else:
            image_ = images
            out_IMAGE = [image_]

            #image_ = tf.image.convert_image_dtype(image_,tf.uint8)
            for i in range(n_jpg):
                blurred_jpg = tf.io.encode_jpeg(image_)
                blurred = tf.io.decode_jpeg(blurred_jpg, q = 95)
                subtracted = tf.cast(image_,dtype=tf.float32)/255 - tf.cast(blurred,dtype=tf.float32)/255
                out_IMAGE = tf.concat([out_IMAGE, subtracted], axis=-1)
                image_ = blurred
            out_IMAGEs +=[out_IMAGE]

        return tf.cast(out_IMAGE,dtype=tf.float32), images, blurred
    # @tf.function
    # def highpass_median(images, kernel_size=11, sigma=5):
    #     blurred = tfa.image.median_filter2d(image=images)#gaussian_blur(images, kernel_size, sigma)
    #     subtracted = images - blurred
    #
    #     return subtracted, images, blurred

    @tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    @tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    def coeffs_by_level(self, coeffs, i, sigma):
        sigma_squared = tf.constant(sigma ** 2, tf.float64)
        h, v, d = coeffs[-1 - i]

        ker3 = tf.ones([3, 3, 3, 3], tf.float64) / (3 ** 2)
        ker5 = tf.ones([5, 5, 3, 3], tf.float64) / (5 ** 2)
        ker7 = tf.ones([7, 7, 3, 3], tf.float64) / (7 ** 2)
        ker9 = tf.ones([9, 9, 3, 3], tf.float64) / (9 ** 2)

        tmp = h ** 2
        var_h3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_h = tf.minimum(var_h3, var_h5)
        var_h = tf.minimum(var_h, var_h7)
        var_h = tf.minimum(var_h, var_h9)

        tmp = v ** 2
        var_v3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_v = tf.minimum(var_v3, var_v5)
        var_v = tf.minimum(var_v, var_v7)
        var_v = tf.minimum(var_v, var_v9)

        tmp = d ** 2
        var_d3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_d = tf.minimum(var_d3, var_d5)
        var_d = tf.minimum(var_d, var_d7)
        var_d = tf.minimum(var_d, var_d9)

        h = h * var_h / (var_h + sigma_squared)
        v = v * var_v / (var_v + sigma_squared)
        d = d * var_d / (var_d + sigma_squared)

        new_coeffs = h, v, d
        return new_coeffs

    def daubechi_filter_without_pywt(self, images, db8, sigma=2.0, return_noise=0):

        """Test"""
        """wavelet_ = Daubechi_wavelet_class.Daubechi_wavelet(2000)
        coeffs = wavelet_.wavedec2(images)
        img_rez = wavelet_.waverec2(coeffs)
        img_rez = tf.minimum(255 * tf.ones_like(img_rez), img_rez)
        img_rez = tf.maximum(tf.zeros_like(img_rez), img_rez)
        img_rez = tf.cast(img_rez, tf.uint8)[0, :, :, :]
        diff = img_rez - images[0, :, :, :]
        max_diff = tf.reduce_max(diff)
        cv2.imshow('filt_img', cv2.cvtColor(img_rez.numpy(), cv2.COLOR_BGR2RGB) )
        cv2.waitKey()"""
        """End test"""

        # height = tf.shape(images)[-3]
        # width = tf.shape(images)[-2]
        # size = tf.maximum(height, width) + tf.constant(50, tf.int32)
        # db8 = Daubechi_wavelet_class.Daubechi_wavelet(size)
        coeffs = db8.wavedec2(images)

        coeffs0 = self.coeffs_by_level(coeffs, 0, sigma)
        coeffs[-1 - 0] = coeffs0
        #uncomment for lvl=4, comment for lvl=1
        # coeffs1 = self.coeffs_by_level(coeffs, 1, sigma)
        # coeffs[-1 - 1] = coeffs1
        # coeffs2 = self.coeffs_by_level(coeffs, 2, sigma)
        # coeffs[-1 - 2] = coeffs2
        # coeffs3 = self.coeffs_by_level(coeffs, 3, sigma)
        # coeffs[-1 - 3] = coeffs3

        filt_img = db8.waverec2(coeffs)
        filt_img = tf.minimum(255 * tf.ones_like(filt_img), filt_img)
        filt_img = tf.maximum(tf.zeros_like(filt_img), filt_img)

        if return_noise > 0:
            noise = tf.cast(images, tf.float64) - filt_img
            result = (noise, images, filt_img)
        else:
            result = filt_img

        return result

    # @tf.function
    def high_db8(self, images, db8, sigma=2.0):
        return self.daubechi_filter_without_pywt(images, db8, sigma=sigma, return_noise=1)

    def haar_filter(self, images, sigma=2.0, return_noise=0):
        level = 1
        coeffs = self.haar_dec2(images, level)


        # for i in tf.range(level):
        coeffs_tmp = self.hcoeffs_by_level(coeffs, 0, sigma)
        coeffs[-1 - 0] = coeffs_tmp


        filt_img = self.haar_rec2(coeffs, level)
        filt_img = tf.minimum(255 * tf.ones_like(filt_img), filt_img)
        filt_img = tf.maximum(tf.zeros_like(filt_img), filt_img)

        # if return_noise > 0:
        #     noise = tf.cast(images, tf.float32) - filt_img
        #     result = (filt_img, noise)
        # else:
        #     result = filt_img
        result = tf.cast(images, tf.float32) - filt_img

        return result



    def haar_dec2(self, batch_bhwc, level=1):
        batch_bhwc = tf.cast(batch_bhwc, tf.float32)


        coeffs_list = []

        low = tf.identity(batch_bhwc)
        # for i in tf.range(level):
        low, hi_coeffs = self.hwt2(low)
        coeffs_list.append(hi_coeffs)

        coeffs_list.append(low)
        coeffs_list.reverse()

        return coeffs_list



    def haar_rec2(self, coeffs, level=1):
        a, ds = coeffs[0], coeffs[1:]


        # for i in tf.range(tf.constant(level, tf.int32)):
        a = self.ihwt2((a, ds[0]))

        return a


    def hwt2(self, batch_bhwc):
        h = (tf.shape(batch_bhwc)[-3] // 2) * 2
        w = (tf.shape(batch_bhwc)[-2] // 2) * 2
        ind_even = tf.range(0, w, 2)
        ind_odd = tf.range(1, w, 2)
        m_even = tf.gather(batch_bhwc, ind_even, axis=2)
        m_odd = tf.gather(batch_bhwc, ind_odd, axis=2)


        half_sum = (m_even + m_odd) / tf.sqrt(2.)
        half_diff = (m_even - m_odd) / tf.sqrt(2.)

        out_step_1 = tf.concat([half_sum, half_diff], axis=2)
        out_step_1 = tf.cond(tf.equal(w, tf.shape(batch_bhwc)[-2]),
                             lambda: out_step_1,
                             lambda: tf.concat([out_step_1, batch_bhwc[:, :, -1:, :]], axis=2)
                             )

        ind_even = tf.range(0, h, 2)
        ind_odd = tf.range(1, h, 2)
        m_even = tf.gather(out_step_1, ind_even, axis=1)
        m_odd = tf.gather(out_step_1, ind_odd, axis=1)
        half_sum = (m_even + m_odd) / tf.sqrt(2.)
        half_diff = (m_even - m_odd) / tf.sqrt(2.)

        out_step_2 = tf.concat([half_sum, half_diff], axis=1)
        out_step_2 = tf.cond(tf.equal(h, tf.shape(batch_bhwc)[-3]),
                             lambda: out_step_2,
                             lambda: tf.concat([out_step_2, out_step_1[:, -1:, :, :]], axis=1)
                             )

        low = out_step_2[:, :(h // 2), :(w // 2), :]
        hor = out_step_2[:, :(h // 2), (w // 2):, :]
        ver = out_step_2[:, (h // 2):, :(w // 2), :]
        dia = out_step_2[:, (h // 2):, (w // 2):, :]

        return low, (hor, ver, dia)


    def ihwt2(self, coeffs):
        low, (hor, ver, dia) = coeffs


        concat_1 = tf.concat([low, hor], axis=2)
        concat_2 = tf.concat([ver, dia], axis=2)
        out_preproc = tf.concat([concat_1, concat_2], axis=1)

        h = tf.shape(out_preproc)[-3] // 2
        w = tf.shape(out_preproc)[-2] // 2

        out = tf.identity(out_preproc)

        updates_even = (out_preproc[:, :h, :, :] + out_preproc[:, h:2 * h, :, :]) / tf.sqrt(2.)
        updates_odd = (out_preproc[:, :h, :, :] - out_preproc[:, h:2 * h, :, :]) / tf.sqrt(2.)

        updates_even = tf.reshape(updates_even, [tf.shape(updates_even)[0] * tf.shape(updates_even)[1] *
                                                 tf.shape(updates_even)[2] * tf.shape(updates_even)[3]])
        updates_odd = tf.reshape(updates_odd, [tf.shape(updates_odd)[0] * tf.shape(updates_odd)[1] *
                                               tf.shape(updates_odd)[2] * tf.shape(updates_odd)[3]])

        start = tf.constant([[1], [0]], tf.float32)
        start = tf.expand_dims(tf.expand_dims(start, 0), -1)
        indexes_basis = tf.tile(start, [tf.shape(out)[0], h, tf.shape(out)[2], tf.shape(out)[3]])
        indexes = tf.cast(tf.where(tf.greater(indexes_basis, 0.5)), tf.int32)
        out = tf.tensor_scatter_nd_update(out, indexes, updates_even)

        indexes = tf.cast(tf.where(tf.less(indexes_basis, 0.5)), tf.int32)
        out = tf.tensor_scatter_nd_update(out, indexes, updates_odd)

        updates_even = (out[:, :, :w, :] + out[:, :, w:2 * w, :]) / tf.sqrt(2.)
        updates_odd = (out[:, :, :w, :] - out[:, :, w:2 * w, :]) / tf.sqrt(2.)

        updates_even = tf.reshape(updates_even, [tf.shape(updates_even)[0] * tf.shape(updates_even)[1] *
                                                 tf.shape(updates_even)[2] * tf.shape(updates_even)[3]])
        updates_odd = tf.reshape(updates_odd, [tf.shape(updates_odd)[0] * tf.shape(updates_odd)[1] *
                                               tf.shape(updates_odd)[2] * tf.shape(updates_odd)[3]])

        start = tf.constant([[1, 0]], tf.float32)
        start = tf.expand_dims(tf.expand_dims(start, 0), -1)
        indexes_basis = tf.tile(start, [tf.shape(out)[0], tf.shape(out)[1], w, tf.shape(out)[3]])
        indexes = tf.cast(tf.where(tf.greater(indexes_basis, 0.5)), tf.int32)
        out = tf.tensor_scatter_nd_update(out, indexes, updates_even)

        indexes = tf.cast(tf.where(tf.less(indexes_basis, 0.5)), tf.int32)
        out = tf.tensor_scatter_nd_update(out, indexes, updates_odd)
        return out

    def hcoeffs_by_level(self, coeffs, i, sigma):
        sigma_squared = tf.constant(sigma ** 2, tf.float32)
        h, v, d = coeffs[-1 - i]


        ker3 = tf.ones([3, 3, 3, 3], tf.float32) / (3 ** 2)
        ker5 = tf.ones([5, 5, 3, 3], tf.float32) / (5 ** 2)
        ker7 = tf.ones([7, 7, 3, 3], tf.float32) / (7 ** 2)
        ker9 = tf.ones([9, 9, 3, 3], tf.float32) / (9 ** 2)

        tmp = h ** 2
        var_h3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_h9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_h = tf.minimum(var_h3, var_h5)
        var_h = tf.minimum(var_h, var_h7)
        var_h = tf.minimum(var_h, var_h9)

        tmp = v ** 2
        var_v3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_v9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_v = tf.minimum(var_v3, var_v5)
        var_v = tf.minimum(var_v, var_v7)
        var_v = tf.minimum(var_v, var_v9)

        tmp = d ** 2
        var_d3 = tf.maximum(tf.nn.conv2d(tmp, ker3, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d5 = tf.maximum(tf.nn.conv2d(tmp, ker5, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d7 = tf.maximum(tf.nn.conv2d(tmp, ker7, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))
        var_d9 = tf.maximum(tf.nn.conv2d(tmp, ker9, [1, 1, 1, 1], "SAME") - sigma_squared, tf.zeros_like(tmp))

        var_d = tf.minimum(var_d3, var_d5)
        var_d = tf.minimum(var_d, var_d7)
        var_d = tf.minimum(var_d, var_d9)

        h = h * var_h / (var_h + sigma_squared)
        v = v * var_v / (var_v + sigma_squared)
        d = d * var_d / (var_d + sigma_squared)

        new_coeffs = h, v, d
        return new_coeffs

    def resize_to(self, image, sz, keep_scales=False):
        if keep_scales == False:
            return tf.image.resize(images=image, size=(sz, sz))
        else:
            return tf.image.resize_with_pad(image=image, target_height=sz, target_width=sz)

    def resize_filter(self, images, scale=1.0/2.0):
        newsize = int(self.resolution * scale)
        # tf.print(newsize)
        rimages = self.resize_to(image=images, sz=newsize, keep_scales=False)
        r2images = self.resize_to(image=rimages, sz=self.resolution, keep_scales=False)
        noise = images - r2images

        return noise

    @tf.function
    def call(self, inputs, training):
        #if inputs.shape[0] != None:
        #print(training)
        #print(type(inputs))
        x = inputs
        #tf.print('":"',tf.shape(x))
        original_shape = tf.shape(x)
        # print('', x)
        #tf.print(tf.shape(x))
        # if training == False:
            # print('********', x)
            # tf.print(tf.shape(x), tf.rank(x))
            # x = tf.cond(tf.rank(x) == 5, lambda : tf.reshape(x, [-1, original_shape[2], original_shape[3], original_shape[4]]), lambda :tf.reshape(x, [-1, original_shape[1], original_shape[2], original_shape[3]]))
            # elif tf.rank(x) == 6:
            #     x = tf.reshape(x, [-1, original_shape[3], original_shape[4], original_shape[5]])
            # x.set_shape([None, None, 64, 64, 3])
            # x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])
            # x.set_shape([None, 64, 64, 3])
        # tf.print(tf.shape(x))
        #print(x.shape)
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])
        original_shape = tf.shape(x)
        #print(x.shape)

        if self.mode == 0:
            x, x_o, x_b = self.highpass_median(x)


        if self.mode != 3:

            x = self.aspp(x)
            print('aspp:',x.shape)
            x = self.conv0(x)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x = self.mp0(x)
            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x = self.mp1(x)
            x = self.conv2(x)
            x = self.bn2(x, training)
            x = self.relu2(x)
            x = self.mp2(x)
            x = self.conv3(x)
            x = self.bn3(x, training)
            x = self.relu3(x)
            x = self.mp3(x)
            x = self.conv4(x)
            x = self.bn4(x, training)
            x = self.relu4(x)
            x = self.mp4(x)

            x = self.conv5(x)
            x = self.bn5(x, training)
            x = self.relu5(x)
            x = self.mp5(x)
            x = self.conv6(x)
            x = self.bn6(x, training)
            x = self.relu6(x)
            x = self.mp6(x)

            x = self.flat(x)
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x
            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}

class Milani2_FPN2Short(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0, av_max=0, n1=3, pass_features=False,schema = [1,1,1,1,1,1,1], n_filters = 512, k_n = 4 , n_p = 512 ,**kwargs):
        super(Milani2_FPN2Short, self).__init__(**kwargs)
        

        self.l2_scale = 0.02
        self.pass_features = pass_features
        self.sh = schema
        
        n_filters = 32*k_n
        
        self.conv0 = tf.keras.layers.Conv2D(filters=8*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up0 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf0 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf0')
        self.add0 = tf.keras.layers.Add()
        self.bna0 = tf.keras.layers.BatchNormalization(name='bn_a0')
        
        if self.sh[0]:
            self.convp0 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp0')
            if av_max:
                self.gp0 = tf.keras.layers.GlobalMaxPooling2D()
            else:
                self.gp0 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv1 = tf.keras.layers.Conv2D(filters=16*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.mp1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up1 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf1 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf1')
        self.add1 = tf.keras.layers.Add()
        self.bna1 = tf.keras.layers.BatchNormalization(name='bn_a1')
        
        if self.sh[1]:
            self.convp1 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp1')
            if av_max:
                self.gp1 = tf.keras.layers.GlobalMaxPooling2D()
            else:
                self.gp1 = tf.keras.layers.GlobalAveragePooling2D()
        
        self.conv2 = tf.keras.layers.Conv2D(filters=24*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv2')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.mp2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up2 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf2 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf2')
        self.add2 = tf.keras.layers.Add()
        self.bna2 = tf.keras.layers.BatchNormalization(name='bn_a2')
        
        if self.sh[2]:
            self.convp2 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp2')
            if av_max:
                self.gp2 = tf.keras.layers.GlobalMaxPooling2D()
            else:
                self.gp2 = tf.keras.layers.GlobalAveragePooling2D()

        self.conv3 = tf.keras.layers.Conv2D(filters=32*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv3')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.mp3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up3 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf3 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf3')
        self.add3 = tf.keras.layers.Add()
        self.bna3 = tf.keras.layers.BatchNormalization(name='bn_a3')
        
        if self.sh[3]:
            self.convp3 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp3')
            if av_max:
                self.gp3 = tf.keras.layers.GlobalMaxPooling2D()
            else:
                self.gp3 = tf.keras.layers.GlobalAveragePooling2D()

        self.conv4 = tf.keras.layers.Conv2D(filters=32*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv4')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()
        self.mp4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.up4 = tf.keras.layers.UpSampling2D(size=(2, 2))
        self.convf4 = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convf4')
        self.add4 = tf.keras.layers.Add()
        self.bna4 = tf.keras.layers.BatchNormalization(name='bn_a4')
        
        if self.sh[4]:
            self.convp4 = tf.keras.layers.Conv2D(filters=n_p, kernel_size=(n1, n1), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convp4')
            if av_max:
                self.gp4 = tf.keras.layers.GlobalMaxPooling2D()
            else:
                self.gp4 = tf.keras.layers.GlobalAveragePooling2D()

        self.dn0 = tf.keras.layers.Dense(units=128, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.flat = tf.keras.layers.GlobalAveragePooling2D()#tf.keras.layers.Flatten(name="features")

        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode

        
        
        
    # @tf.function
    def gaussian_blur(self, img, kernel_size=11, sigma=5):
        def gauss_kernel(channels, kernel_size, sigma):
            ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)
            xx, yy = tf.meshgrid(ax, ax)
            kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))
            kernel = kernel / tf.reduce_sum(kernel)
            kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])
            return kernel

        gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)
        gaussian_kernel = gaussian_kernel[..., tf.newaxis]

        return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1], padding='SAME', data_format='NHWC')

    # @tf.function
    def highpass(self, images, kernel_size=11, sigma=5):
        blurred = self.gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    # @tf.function
    # def highpass_median(images, kernel_size=11, sigma=5):
    #     blurred = tfa.image.median_filter2d(image=images)#gaussian_blur(images, kernel_size, sigma)
    #     subtracted = images - blurred
    #
    #     return subtracted, images, blurred

    #  ...........@tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    # ,,,,@  ,,,,,tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred


    def resize_to(self, image, sz, keep_scales=False):
        if keep_scales == False:
            return tf.image.resize(images=image, size=(sz, sz))
        else:
            return tf.image.resize_with_pad(image=image, target_height=sz, target_width=sz)

    def resize_filter(self, images, scale=1.0/2.0):
        newsize = int(self.resolution * scale)
        # tf.print(newsize)
        rimages = self.resize_to(image=images, sz=newsize, keep_scales=False)
        r2images = self.resize_to(image=rimages, sz=self.resolution, keep_scales=False)
        noise = images - r2images

        return noise

    #  ,,,@ tf.function
    def call(self, inputs, training):  
        
        x = inputs
        #tf.print('":"',tf.shape(x))
        original_shape = tf.shape(x)
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])

        if self.mode == 0:
                #print(x.shape)
                #x, x_o, x_b = self.highpass_median(x)
                #x, x_o, x_b = self.jpeg_dif( x, n_jpg=2,q=95, q_Im=10.)
                x, x_o, x_b = self.highpass_median(x)


        if self.mode == 0:
            x = self.conv0(x)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x0 = x
            x = self.mp0(x)

            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x1 = x
            x = self.mp1(x)

            x = self.conv2(x)
            x = self.bn2(x, training)
            x = self.relu2(x)
            x2 = x
            x = self.mp2(x)

            x = self.conv3(x)
            x = self.bn3(x, training)
            x = self.relu3(x)
            x3 = x
            x = self.mp3(x)

            x = self.conv4(x)
            x = self.bn4(x, training)
            x = self.relu4(x)
            x4 = x
            x = self.mp4(x)


            x5 = x

            list_x = []
 
 
            x45 = self.up4(x5)
            print('4:',x45.shape)
            x4 = self.convf4(x4)
            print('4:',x4.shape)
            x45 = self.add4([x4,x45])
            x45 = self.bna4(x45)
            print('4:',x4.shape, x45.shape)
            if self.sh[3]:
                x45_ = self.convp4(x45)
                print('4:',x45_.shape)
                x45g = self.gp4(x45_)
                print('4:',x45.shape)
                list_x += [x45g]

            x34 = self.up3(x45)
            x3 = self.convf3(x3)
            x34 = self.add3([x3,x34])
            x34 = self.bna3(x34)
            print('3:',x3.shape, x34.shape)
            if self.sh[2]:
                x34_ = self.convp3(x34)
                x34g = self.gp3(x34_)
                list_x += [x34g]

            x23 = self.up2(x34)
            x2 = self.convf2(x2)
            x23 = self.add2([x2,x23])
            x23 = self.bna2(x23)
            print('2:',x2.shape, x23.shape)
            if self.sh[1]:
                x23_ = self.convp3(x23)
                x23g = self.gp2(x23_)
                list_x += [x23g]

            x12 = self.up1(x23)
            x1 = self.convf1(x1)
            x12 = self.add1([x1,x12])
            x12 = self.bna1(x12)
            print('1:',x1.shape, x12.shape)
            if self.sh[0]:
                x12_ = self.convp2(x12)
                x12g = self.gp2(x12_)
                list_x += [x12g]

            x = self.flat(x)
            if self.sh[6]:
                x = tf.keras.layers.concatenate(list_x + [x])
            else:
                x = tf.keras.layers.concatenate(list_x )
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x
            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}

class Patches(tf.keras.layers.Layer):
    def __init__(self, patch_size):
        super(Patches, self).__init__()
        self.patch_size = patch_size

    def call(self, images):
        batch_size = tf.shape(images)[0]
        patches = tf.image.extract_patches(
            images=images,
            sizes=[1, self.patch_size, self.patch_size, 1],
            strides=[1, self.patch_size, self.patch_size, 1],
            rates=[1, 1, 1, 1],
            padding="VALID",
        )
        patch_dims = patches.shape[-1]
        patches = tf.reshape(patches, [batch_size, -1,  self.patch_size, self.patch_size, 3])
        return patches    
    
class Milani2_FPNlstm(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, classes, constructing_pipeline=False, mode=0, av_max=0, n1=3,k_n=1, patch_aug  = 0,pass_features=False, **kwargs):
        super(Milani2_FPNlstm, self).__init__(**kwargs)

        self.l2_scale = 0.02
        self.pass_features = pass_features
        self.patch_aug = patch_aug
        
        self.conv0 = tf.keras.layers.Conv2D(filters=4*k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        
        self.conv1 = tf.keras.layers.Conv2D(filters=k_n*8, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.mp1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))        
        
        self.conv2 = tf.keras.layers.Conv2D(filters=k_n*12, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv2')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.mp2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
    

        self.conv3 = tf.keras.layers.Conv2D(filters=k_n*16, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv3')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.mp3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        
        self.conv4 = tf.keras.layers.Conv2D(filters=k_n*16, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv4')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()
        self.mp4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

                
        self.conv5 = tf.keras.layers.Conv2D(filters=k_n*32, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv5')
        self.bn5 = tf.keras.layers.BatchNormalization(name='bn_5')
        self.relu5 = tf.keras.layers.ReLU()
        self.mp5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))


        
        self.conv6 = tf.keras.layers.Conv2D(filters=k_n*64, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv6')
        self.bn6 = tf.keras.layers.BatchNormalization(name='bn_6')
        self.relu6 = tf.keras.layers.ReLU()
        self.mp6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

 
        self.patch = Patches(16)
        self.lstm1 = tf.keras.layers.ConvLSTM2D(filters=k_n*2, kernel_size=(3,3), strides=(1, 1), padding='same', stateful = False, return_sequences= True)
        self.lstm2 = tf.keras.layers.ConvLSTM2D(filters=k_n*2, kernel_size=(3,3), strides=(1, 1), padding='same', return_sequences= False)
        self.convlstm = tf.keras.layers.Conv2D(filters=k_n, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='convlstm')
        self.bnlstm = tf.keras.layers.BatchNormalization(name='bn_lstm')
        self.relulstm = tf.keras.layers.ReLU()        
        
        self.dn0 = tf.keras.layers.Dense(units=k_n*16, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.flat = tf.keras.layers.Flatten(name="features")
       
        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        
    #@tf.function
    def gaussian_blur(self, img, kernel_size=11, sigma=5):
        def gauss_kernel(channels, kernel_size, sigma):
            ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)
            xx, yy = tf.meshgrid(ax, ax)
            kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))
            kernel = kernel / tf.reduce_sum(kernel)
            kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])
            return kernel

        gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)
        gaussian_kernel = gaussian_kernel[..., tf.newaxis]

        return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1], padding='SAME', data_format='NHWC')

    #@tf.function
    def highpass(self, images, kernel_size=11, sigma=5):
        blurred = self.gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    # @tf.function
    # def highpass_median(images, kernel_size=11, sigma=5):
    #     blurred = tfa.image.median_filter2d(image=images)#gaussian_blur(images, kernel_size, sigma)
    #     subtracted = images - blurred
    #
    #     return subtracted, images, blurred

    #@tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    #@tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred



    def resize_to(self, image, sz, keep_scales=False):
        if keep_scales == False:
            return tf.image.resize(images=image, size=(sz, sz))
        else:
            return tf.image.resize_with_pad(image=image, target_height=sz, target_width=sz)

    def resize_filter(self, images, scale=1.0/2.0):
        newsize = int(self.resolution * scale)
        # tf.print(newsize)
        rimages = self.resize_to(image=images, sz=newsize, keep_scales=False)
        r2images = self.resize_to(image=rimages, sz=self.resolution, keep_scales=False)
        noise = images - r2images

        return noise
    
    #@tf.function
    def call(self, inputs, training):

        x = inputs
        #tf.print('":"',tf.shape(x))
        original_shape = tf.shape(x)
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])

        if self.mode == 0:
                #print(x.shape)
                #x, x_o, x_b = self.highpass_median(x)
                #x, x_o, x_b = self.jpeg_dif( x, n_jpg=2,q=95, q_Im=10.)
                x, x_o, x_b = self.highpass_median(x)
                
        x_in = x
        x_lstm = self.patch(x_in) 
        print(x_lstm.shape)
        if self.mode == 0:
            x_lstm = self.lstm1(x_lstm)
            print(x_lstm.shape)
            x_lstm = self.lstm2(x_lstm)
            print(x_lstm.shape)
            x_lstm = self.convlstm(x_lstm)
            x_lstm = self.bnlstm(x_lstm, training)
            x_lstm = self.relulstm(x_lstm)            
                                             
                                             
            x = self.conv0(x_in)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x0 = x
            x = self.mp0(x)
            
            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x1 = x
            x = self.mp1(x)
            
            x = self.conv2(x)
            x = self.bn2(x, training)
            x = self.relu2(x)
            x2 = x
            x = self.mp2(x)
            
            x = self.conv3(x)
            x = self.bn3(x, training)
            x = self.relu3(x)
            x3 = x
            
            x = tf.keras.layers.concatenate([x_lstm,x])
            x = self.mp3(x)
            
            x = self.conv4(x)
            x = self.bn4(x, training)
            x = self.relu4(x)
            x4 = x
            x = self.mp4(x)

            x = self.conv5(x)
            x = self.bn5(x, training)
            x = self.relu5(x)
            x5 = x
            x = self.mp5(x)
            
            x = self.conv6(x)
            x = self.bn6(x, training)
            x = self.relu6(x)
            x6 = x
            x = self.mp6(x)
            
            x7 = x
                        
            x = self.flat(x)
            
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x
            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}

class Milani2_m(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, 
                 classes, constructing_pipeline=False, mode=0, av_max=0, 
                 n1=4, fgsm =0.0 , pass_features=False, **kwargs):
        super(Milani2_m, self).__init__(**kwargs)

        self.l2_scale = 0.02
        self.pass_features = pass_features

        self.conv0 = tf.keras.layers.Conv2D(filters=8*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.conv1 = tf.keras.layers.Conv2D(filters=16*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.mp1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))        
        
        self.conv2 = tf.keras.layers.Conv2D(filters=28*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv2')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.mp2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))

        self.conv3 = tf.keras.layers.Conv2D(filters=32*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv3')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.mp3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))
        
        self.conv4 = tf.keras.layers.Conv2D(filters=32*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv4')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()
        self.mp4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))


                
        self.conv5 = tf.keras.layers.Conv2D(filters=64*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv5')
        self.bn5 = tf.keras.layers.BatchNormalization(name='bn_5')
        self.relu5 = tf.keras.layers.ReLU()
        self.mp5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))


        
        self.conv6 = tf.keras.layers.Conv2D(filters=128*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv6')
        self.bn6 = tf.keras.layers.BatchNormalization(name='bn_6')
        self.relu6 = tf.keras.layers.ReLU()
        self.mp6 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))


        
        self.dn0 = tf.keras.layers.Dense(units=32*n1, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.flat = tf.keras.layers.Flatten(name="features")
       
        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        
        self.fgsm = fgsm
        
        self.loss_object = tf.keras.losses.CategoricalCrossentropy()
        
    #@tf.function
    def gaussian_blur(self, img, kernel_size=11, sigma=5):
        def gauss_kernel(channels, kernel_size, sigma):
            ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)
            xx, yy = tf.meshgrid(ax, ax)
            kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))
            kernel = kernel / tf.reduce_sum(kernel)
            kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])
            return kernel

        gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)
        gaussian_kernel = gaussian_kernel[..., tf.newaxis]

        return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1], padding='SAME', data_format='NHWC')

    #@tf.function
    def highpass(self, images, kernel_size=11, sigma=5):
        blurred = self.gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    # @tf.function
    # def highpass_median(images, kernel_size=11, sigma=5):
    #     blurred = tfa.image.median_filter2d(image=images)#gaussian_blur(images, kernel_size, sigma)
    #     subtracted = images - blurred
    #
    #     return subtracted, images, blurred

    #@tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    #@tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred


    def resize_to(self, image, sz, keep_scales=False):
        if keep_scales == False:
            return tf.image.resize(images=image, size=(sz, sz))
        else:
            return tf.image.resize_with_pad(image=image, target_height=sz, target_width=sz)

    def resize_filter(self, images, scale=1.0/2.0):
        newsize = int(self.resolution * scale)
        # tf.print(newsize)
        rimages = self.resize_to(image=images, sz=newsize, keep_scales=False)
        r2images = self.resize_to(image=rimages, sz=self.resolution, keep_scales=False)
        noise = images - r2images

        return noise
    
    #FGSM     
        

    def train_step(self, data):
        x, y = data
        #try:
        if 0:    
            with tf.GradientTape() as tape:
                #print('FGSM')
                #print(x)
                tape.watch(x)
                y_pred = self(x, training=False)  # Forward pass
                # Compute our own loss
                #print('y_pred:',y_pred["logits_softmax"])
                #print('y:',y)
                loss = self.loss_object(y, y_pred["logits_softmax"])
                #print('loss:',loss)
            gradient = tape.gradient(loss, x) 
            #print(gradient)
            signed_grad = tf.sign(gradient)
            x = x + gradient* self.fgsm
                
            #print('fgsm:',x.shape, self.fgsm)
        #except:
        #    pass
        return super(Milani2_m,self).train_step((x,y))
        

    @tf.function
    def call(self, inputs, training):
        #print(inputs)
        if isinstance(inputs,tuple):
            x = inputs[0]
        else:
            x = inputs
        #tf.print('":"',tf.shape(x))
        original_shape = x.shape
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])

        if self.mode == 0:
                #print(x.shape)
                #x, x_o, x_b = self.highpass_median(x)
                #x, x_o, x_b = self.jpeg_dif( x, n_jpg=2,q=95, q_Im=10.)
                x, x_o, x_b = self.highpass_median(x)
                

        if 1:
            x = self.conv0(x)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x = self.mp0(x)
            
            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x = self.mp1(x)
            
            x = self.conv2(x)
            x = self.bn2(x, training)
            x = self.relu2(x)
            x = self.mp2(x)
            
            x = self.conv3(x)
            x = self.bn3(x, training)
            x = self.relu3(x)
            x = self.mp3(x)
            
            x = self.conv4(x)
            x = self.bn4(x, training)
            x = self.relu4(x)
            x = self.mp4(x)

            x = self.conv5(x)
            x = self.bn5(x, training)
            x = self.relu5(x)
            x = self.mp5(x)
            
            x = self.conv6(x)
            x = self.bn6(x, training)
            x = self.relu6(x)
            x = self.mp6(x)
            
            
            
            x = self.flat(x)
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x

            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}


class Milani2_c(tf.keras.Model):
    def __init__(self, resolution, dropout, num_features, 
                 classes, constructing_pipeline=False, mode=0, av_max=0, 
                 n1=4, fgsm =0.0 , pass_features=False, **kwargs):
        super(Milani2_c, self).__init__(**kwargs)

        self.l2_scale = 0.02
        self.pass_features = pass_features

        self.conv0 = tf.keras.layers.Conv2D(filters=8*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv0')
        self.bn0 = tf.keras.layers.BatchNormalization(name='bn_0')
        self.relu0 = tf.keras.layers.ReLU()
        self.mp0 = tf.keras.layers.Conv2D(filters=8*n1, kernel_size=(3, 3), strides=(2, 2), padding="SAME", activation='relu', kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv01')
        
        self.conv1 = tf.keras.layers.Conv2D(filters=16*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv1')
        self.bn1 = tf.keras.layers.BatchNormalization(name='bn_1')
        self.relu1 = tf.keras.layers.ReLU()
        self.mp1 = tf.keras.layers.Conv2D(filters=16*n1, kernel_size=(3, 3), strides=(2, 2), padding="SAME", activation='relu', kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv11')        
        
        self.conv2 = tf.keras.layers.Conv2D(filters=28*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv2')
        self.bn2 = tf.keras.layers.BatchNormalization(name='bn_2')
        self.relu2 = tf.keras.layers.ReLU()
        self.mp2 = tf.keras.layers.Conv2D(filters=28*n1, kernel_size=(3, 3), strides=(2, 2), padding="SAME", activation='relu', kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv21')

        self.conv3 = tf.keras.layers.Conv2D(filters=32*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv3')
        self.bn3 = tf.keras.layers.BatchNormalization(name='bn_3')
        self.relu3 = tf.keras.layers.ReLU()
        self.mp3 = tf.keras.layers.Conv2D(filters=32*n1, kernel_size=(3, 3), strides=(2, 2), padding="SAME", activation='relu', kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv31')
        
        self.conv4 = tf.keras.layers.Conv2D(filters=32*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv4')
        self.bn4 = tf.keras.layers.BatchNormalization(name='bn_4')
        self.relu4 = tf.keras.layers.ReLU()
        self.mp4 = tf.keras.layers.Conv2D(filters=32*n1, kernel_size=(3, 3), strides=(2, 2), padding="SAME", activation='relu', kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv41')


                
        self.conv5 = tf.keras.layers.Conv2D(filters=64*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv5')
        self.bn5 = tf.keras.layers.BatchNormalization(name='bn_5')
        self.relu5 = tf.keras.layers.ReLU()
        self.mp5 = tf.keras.layers.Conv2D(filters=64*n1, kernel_size=(3, 3), strides=(2, 2), padding="SAME", activation='relu', kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv51')


        
        self.conv6 = tf.keras.layers.Conv2D(filters=128*n1, kernel_size=(3, 3), strides=(1, 1), padding="SAME", activation=None, kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv6')
        self.bn6 = tf.keras.layers.BatchNormalization(name='bn_6')
        self.relu6 = tf.keras.layers.ReLU()
        self.mp6 = tf.keras.layers.Conv2D(filters=128*n1, kernel_size=(3, 3), strides=(2, 2), padding="SAME", activation='relu', kernel_initializer=tf.keras.initializers.glorot_normal(), name='conv61')


        
        self.dn0 = tf.keras.layers.Dense(units=32*n1, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())
        self.dropout = tf.keras.layers.Dropout(0.5, name="dropout")
        self.dn1 = tf.keras.layers.Dense(units=2, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform())

        self.flat = tf.keras.layers.Flatten(name="features")
       
        self.resolution = resolution
        self.constructing = constructing_pipeline
        self.mode = mode
        
        self.fgsm = fgsm
        
        self.loss_object = tf.keras.losses.CategoricalCrossentropy()
        
    #@tf.function
    def gaussian_blur(self, img, kernel_size=11, sigma=5):
        def gauss_kernel(channels, kernel_size, sigma):
            ax = tf.range(-kernel_size // 2 + 1.0, kernel_size // 2 + 1.0)
            xx, yy = tf.meshgrid(ax, ax)
            kernel = tf.exp(-(xx ** 2 + yy ** 2) / (2.0 * sigma ** 2))
            kernel = kernel / tf.reduce_sum(kernel)
            kernel = tf.tile(kernel[..., tf.newaxis], [1, 1, channels])
            return kernel

        gaussian_kernel = gauss_kernel(tf.shape(img)[-1], kernel_size, sigma)
        gaussian_kernel = gaussian_kernel[..., tf.newaxis]

        return tf.nn.depthwise_conv2d(img, gaussian_kernel, [1, 1, 1, 1], padding='SAME', data_format='NHWC')

    #@tf.function
    def highpass(self, images, kernel_size=11, sigma=5):
        blurred = self.gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred

    # @tf.function
    # def highpass_median(images, kernel_size=11, sigma=5):
    #     blurred = tfa.image.median_filter2d(image=images)#gaussian_blur(images, kernel_size, sigma)
    #     subtracted = images - blurred
    #
    #     return subtracted, images, blurred

    #@tf.function
    def mean_filter2d(self, image, filter_shape=(3, 3), name=None):
        with tf.name_scope(name or "mean_filter2d"):
            image = tf.convert_to_tensor(image, name="image")

            rank = image.shape.rank
            if rank != 3 and rank != 4:
                raise ValueError("image should be either 3 or 4-dimensional.")

            # Expand to a 4-D tensor
            if rank == 3:
                image = tf.expand_dims(image, axis=0)

            area = filter_shape[0] * filter_shape[1]
            filter_shape = filter_shape + (tf.shape(image)[-1], 1)
            kernel = tf.ones(shape=filter_shape, dtype=image.dtype) / area

            output = tf.nn.depthwise_conv2d(
                image, kernel, strides=(1, 1, 1, 1), padding="SAME")

            if rank == 3:
                output = tf.squeeze(output, axis=0)

            return output

    #@tf.function
    def highpass_median(self, images, kernel_size=11, sigma=5):
        blurred = self.mean_filter2d(image=images)  # tf.map_fn(lambda x: median_filter(data=x), images)#tfa.image.median_filter2d(image=images)  # gaussian_blur(images, kernel_size, sigma)
        subtracted = images - blurred

        return subtracted, images, blurred


    def resize_to(self, image, sz, keep_scales=False):
        if keep_scales == False:
            return tf.image.resize(images=image, size=(sz, sz))
        else:
            return tf.image.resize_with_pad(image=image, target_height=sz, target_width=sz)

    def resize_filter(self, images, scale=1.0/2.0):
        newsize = int(self.resolution * scale)
        # tf.print(newsize)
        rimages = self.resize_to(image=images, sz=newsize, keep_scales=False)
        r2images = self.resize_to(image=rimages, sz=self.resolution, keep_scales=False)
        noise = images - r2images

        return noise
    
    #FGSM     
        

    def train_step(self, data):
        x, y = data
        #try:
        if 0:    
            with tf.GradientTape() as tape:
                #print('FGSM')
                #print(x)
                tape.watch(x)
                y_pred = self(x, training=False)  # Forward pass
                # Compute our own loss
                #print('y_pred:',y_pred["logits_softmax"])
                #print('y:',y)
                loss = self.loss_object(y, y_pred["logits_softmax"])
                #print('loss:',loss)
            gradient = tape.gradient(loss, x) 
            #print(gradient)
            signed_grad = tf.sign(gradient)
            x = x + gradient* self.fgsm
                
            #print('fgsm:',x.shape, self.fgsm)
        #except:
        #    pass
        return super(Milani2_c,self).train_step((x,y))
        

    @tf.function
    def call(self, inputs, training):
        #print(inputs)
        if isinstance(inputs,tuple):
            x = inputs[0]
        else:
            x = inputs
        #tf.print('":"',tf.shape(x))
        original_shape = x.shape
        x = tf.reshape(x, [-1, self.resolution, self.resolution, 3])

        if self.mode == 0:
                #print(x.shape)
                #x, x_o, x_b = self.highpass_median(x)
                #x, x_o, x_b = self.jpeg_dif( x, n_jpg=2,q=95, q_Im=10.)
                x, x_o, x_b = self.highpass_median(x)
                

        if 1:
            x = self.conv0(x)
            x = self.bn0(x, training)
            x = self.relu0(x)
            x = self.mp0(x)
            
            x = self.conv1(x)
            x = self.bn1(x, training)
            x = self.relu1(x)
            x = self.mp1(x)
            
            x = self.conv2(x)
            x = self.bn2(x, training)
            x = self.relu2(x)
            x = self.mp2(x)
            
            x = self.conv3(x)
            x = self.bn3(x, training)
            x = self.relu3(x)
            x = self.mp3(x)
            
            x = self.conv4(x)
            x = self.bn4(x, training)
            x = self.relu4(x)
            x = self.mp4(x)

            x = self.conv5(x)
            x = self.bn5(x, training)
            x = self.relu5(x)
            x = self.mp5(x)
            
            x = self.conv6(x)
            x = self.bn6(x, training)
            x = self.relu6(x)
            x = self.mp6(x)
            
            
            
            x = self.flat(x)
            f = x
            x = self.dn0(x)
            x = self.dropout(x, training)
            x = self.dn1(x)

            logits = x
            if training == False:
                logits = tf.reshape(logits, [original_shape[0], -1, 2])

        if self.pass_features == True:
            return {"logits": logits, "logits_softmax": tf.nn.softmax(logits), "features": f}
        return {"logits": logits, "logits_softmax": tf.nn.softmax(logits)}#, "embeddings": f, "features": f}    
